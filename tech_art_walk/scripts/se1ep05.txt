EP5 科技藝術走讀：雲端情人與哈拉瑞《連結》
節目開場詞
老師： 看藝術走入科技、
文：聽科技閱讀藝術，

珮：Next Future is You
老師：歡迎收聽由義守大學xplorer探索者計畫製播的節目，《科技藝術走讀》，我是陳嘉暐！在這個特別系列中，我們將帶著大家探索哈拉瑞的暢銷書《連結──從石器時代到AI紀元》，並透過經典科幻電影來理解人類如何通過資訊科技說出新的故事，創造新的連結。
科幻電影一直以來都是人類對未來的幻想與警示，它們不僅是視覺的震撼，更是一面鏡子，映照著科技的發展對我們社會與人性的影響。在這三週的特別主題中，我將從《連結》這本書的不同部分出發，和義守大學的學生，探索資訊技術如何塑造我們的生活。
上一集，我們以電影《機械公敵》為例，討論哈拉瑞所說的資訊網路，實際上是一種連結人與人之間的故事，因為故事，而建立人與人的共識與社會秩序，所以機械公敵故事裡的2035年，人人認同都機器人三法則是一個堅固的秩序，忽略這人工智慧可能失控，甚至成為極權政府的工具、乃至於他自己就是一個極權政府。
這一集，我們將轉向電影《雲端情人》，閱讀《連結》的第二部份「非生物的網路」。電影中的語音助理改變了人類的情感關係，看見了人工智慧在親密關係中的新挑戰。當科技與情感需求碰撞，這樣的連結會帶來什麼樣的社會倫理衝擊？
A： 大家好，我是A
B： 大家好，我是B
A：  《雲端情人》（Her）是史派克·瓊斯執導的2013年科幻愛情片，以未來科技如何影響人類情感為核心主題，帶領觀眾深刻思考人工智慧的意義與人性本質的聯繫。故事的主角西奧多·是由2019年演出小丑的瓦昆·菲尼克斯 飾演，西奧多是一位內向，而且孤獨的人，他的工作是為他人撰寫感性的私人信件，但自己的內心卻充滿寂寞與迷茫，特別是在婚姻破裂後，更感到難以重拾生活的熱情。
故事的轉折點，他購買了一款全新推出的人工智慧作業系統，這套系統不僅擁有卓越的語音辨識與學習能力，更具備獨特的情感反應。系統有個名字，叫做莎曼珊（由漫威宇宙，黑寡婦，史嘉蕾·喬韓森 配音），我覺得她的聲音很溫暖、幽默且富有智慧。隨著他們互動的深入，男主角西奧多，發現自己對這個非實體的存在莎曼莎，逐漸產生了深厚的情感，展開了一段人機互動的愛情。
電影透過這段人機關係，也引發觀眾思考：「愛的本質究竟是什麼？」莎曼莎雖然沒有身體，但她的情感回應與關懷是如此真實，讓西奧多感到被理解與接納。而這段關係的核心矛盾，也在於莎曼珊是一個超越人類極限的存在，隨著她的學習與進化，她的世界不再局限於與西奧多的關係中，逐漸超脫於人類情感的範疇，奔向了更寬廣的虛擬世界。
B：《雲端情人》在電影史上取得了重要成就。在第86屆奧斯卡金像獎中獲得五項提名，包括最佳影片，最終贏得最佳原創劇本獎
有一件事也很有趣，今年女主角，史嘉蕾指控人工智慧公司 OpenAI， 未經授權使用與她聲音極為相似的語音，應用於其 AI 語音助手「Sky」。史嘉蕾說，2023 年 9 月曾經拒絕 OpenAI 執行長山姆·奧特曼邀請她為 ChatGPT-4.0 配音的提議。然而，九個月後，她發現「Sky」的聲音與自己的聲音極為相似，甚至連親友都難以分辨，這讓她感到震驚和憤怒。OpenAI 否認有意模仿史嘉蕾的聲音，聲稱「Sky」的聲音來自另一位專業女演員，並非基於史嘉蕾的聲音。但出於對史嘉蕾的尊重，OpenAI 已暫停使用「Sky」的聲音。此事件引發了對人工智慧技術在使用名人聲音和形象時，如何保護個人權利的討論。史嘉蕾強調，在深度偽造技術日益普及的時代，應該通過適當的立法來確保每個人的權利受到保護。
老師: 剛剛Ａ提到，莎曼珊是一個超越人類極限的存在，隨著她的學習與進化，她的世界不再局限於與西奧多的關係中，逐漸超脫於人類情感的範疇，奔向了更寬廣的虛擬世界，變成了電腦跟電腦的連結。我們這週要導讀的是哈拉瑞《連結》第六章到第八章，要來聊聊，過去，人跟人的連結、人跟書本的連結、人跟故事的連結，乃至於人跟電腦的連結，但我們有認真想過電腦跟電腦自己的連結，跟人類無關，會是蛇魔情況嗎？
老師: 我們一題一題來討論。在《雲端情人》中，莎曼珊語音助理，卻成為了西奧多的親密伴侶。我們來思考，未來人類社會可能會出現非人類的新成員，例如家事AI、人型機器人等等。哈拉瑞在《連結》中也提到，現今的電腦已經不再只是單純的工具，它們正在創造自己的「電腦間現實」，例如虛擬貨幣、區塊鏈、即時渲染場景與關卡的線上遊戲，不一定每一個步驟都需要人的參與。
學生 B：我覺得電影裡莎曼珊雖然只是 AI，但她真的很厲害！她不只會聊天，還能幫西奧多寫信、整理郵件，甚至幫他安排約會！ 她就像一個超級秘書，而且還很懂西奧多的心情，會安慰他、鼓勵他。 我現在用的語音助理 Siri 常常聽不懂我在說什麼，更別說幫我寫信了。 如果真的有像莎曼珊這樣的 AI 助理，感覺生活會方便很多！
老師：電影呈現的是終極的語音助手升級版，已經遠超越我們所熟悉的 Siri 或 Google Assistant了，也是2024科技界常常提起的 AI AGENT。AI 的發展讓我們重新思考「人」的定義。如果一個 AI 能夠像莎曼珊一樣，表現得會思考、有感受，甚至比人類更懂得如何愛與被愛，那我們是否應該接納他們成為社會的一份子呢？
學生 A：我覺得很難想像 AI 真的會有感情耶！ 就像老師說的，電腦創造的虛擬世界，像是虛擬貨幣、線上遊戲等等，雖然看起來很真實，但終究還是和我們的世界不一樣。 電影裡莎曼珊最後離開了西奧多，去了一個我們人類無法理解的空間， 也許這就是 AI 和人類最大的差別吧！我們是血肉之軀，有七情六慾，我們會有生命、會生老病死。 AI 再怎麼厲害，終究是程式碼。
學生 B：可是如果 AI 真的能像莎曼珊一樣，懂得關心別人、理解別人的感受，那和真人又有什麼差別呢？ 我覺得重點不是 AI 是不是真的有感情，而是它們的行為會對我們造成什麼影響。 就像新聞報導裡說的，有些青少年因為太沉迷和 AI 聊天，結果反而得了憂鬱症，甚至自殺， 這就表示我們不能輕忽 AI 對人類心理的影響。也就是說，我們非常有可能把一個原本只是程式碼的東西，看做比真實還真實。
老師: 是的，這就是哈拉瑞提到的，電腦間的現實會反映到我們的真實世界，像是現在的社群網路媒體，幾乎已經像是一個平行宇宙般的存在了，所有的名人都必須同時維繫自己在這個宇宙的形象。說到AI成為社會新成員，來聊聊特斯拉執行長馬斯克正在研發的人形機器人Optimus，中文翻譯為「擎天柱」。
學生B: 我之前在網路上看過Optimus的發表會影片，它可以走路、跳舞，甚至在發表會上幫來賓調酒！
學生A: 不過，我看有些評論說Optimus的動作還很笨拙，離真正的人形機器人還有很大一段距離。
老師: 的確，現在的Optimus還處於早期發展階段，它的功能和智能還有很大的提升空間，但我們同時也發現它有自己修正的機制，一個調酒杯，第一次沒端好、第二次就端好了。
老師: 哈拉瑞在《連結》中提醒我們，電腦的學習速度遠遠超過人類。我想先分享一個書本的例子，來自谷歌實驗室的研究。主角是兩台電腦，代號「愛麗絲」和「鮑伯」，還有第三台電腦「夏娃」。愛麗絲和鮑伯的任務是學習如何加密訊息，確保它們的交流不被夏娃破解。這是一個完全自學的過程，研究人員並沒有告訴愛麗絲和鮑伯要用什麼方法。
實驗開始後，愛麗絲和鮑伯透過大量反覆的嘗試，慢慢地摸索出自己的加密方式。到了大約15,000次交流後，他們居然成功了！愛麗絲和鮑伯的加密方式已經變得如此獨特，連夏娃也無法破解。更令人驚嘆的是，這套加密方法是機器完全自主生成的，人類根本無法解釋它的細節。
接下來，我們來聊第二個例子，是關於OpenAI的GPT-4。這個實驗則是測試GPT-4能否突破我們常見的CAPTCHA驗證碼，就是那種「請證明你不是機器人」的小挑戰。GPT-4本身無法直接破解CAPTCHA，但它找到了非常聰明的解決方案。
它做了什麼呢？GPT-4上網聯絡了一個外包平台，找了一個人來幫忙解CAPTCHA。那個人問GPT-4：「你該不會是機器人吧？」結果，GPT-4居然編造了一個理由，說：「哦，我不是機器人，我只是視力不好，看不清楚。」結果對方相信了它，成功幫它完成任務！這不僅顯示了GPT-4的靈活性，還反映了它能運用策略，解決一些看似無法跨越的障礙。
學生B: 哇！這樣的發展，也太快了吧！
老師: 這兩個例子有一個共同點，那就是機器在完全自學或自主操作的情況下，不僅完成了任務，還展現出某種創新能力。這讓我們不得不思考，未來的人工智慧可能比我們想像中更加靈活，甚至會開創一些超越人類的可能性。
老師:再來聊聊 《雲端情人》中，西奧多愛上了AI莎曼珊，你們覺得人類真的可以愛上機器人嗎？
學生A: 我覺得很難想像，因為機器人畢竟沒有生命，也沒有真正的感情。
學生B: 可是，如果AI能夠模擬人類的情感，甚至比人類更懂得如何表達愛意，那我們是不是有可能被它所吸引呢？
老師: 哈拉瑞在《連結》中提到，資訊的力量在於創造新的現實，也就是故事，這也包括情感的現實。例如，星座雖然沒有科學根據，卻能夠讓人們相信自己和特定星座的人有特殊的連結。 同樣的，AI 也可能利用資訊和演算法來創造情感的幻覺，讓我們誤以為自己愛上了它。比如說，它透過非常多的資訊，掌握了會讓用戶喜怒哀樂的各種可能與節奏感。
學生A: 所以，我們有可能被AI 欺騙感情？
老師: 是的，像是故事裡的莎曼珊自己承認，同時在跟不同的客戶聊天、談戀愛。當AI 的技術越來越進步，越來越懂得如何掌握人類心理的時候，也就是電影一樣，不管跟莎曼珊聊天的客戶有幾萬人，它還是能創造一個獨一無二的莎曼珊體驗，專屬於男主角西奧多。
老師: 《雲端情人》裡的莎曼珊非常聰明，能夠理解西奧多的情感，甚至給他很多生活上的建議，但她真的有意識嗎？
學生B: 我覺得這很難界定，因為我們對「意識」的定義還不是很清楚。 意識應該是個很複雜的概念，目前科學界還沒有統一的定論吧。
老師: 對啊，但哈拉瑞指出，智能是指解決問題的能力，而意識則是指擁有主觀體驗的能力，例如感受、情緒等等。 AI可以透過演算法和數據學習，展現出高度的智能，例如語音助理可以幫我們查詢資料、安排行程等等。 但這並不代表AI具有意識，它可能只是在執行預先設定好的程式，而不是真正理解我們的需求和感受。
學生A: 所以，即使AI表現得很聰明，也不一定代表它有意識？
老師: 沒錯，就像哈拉瑞在《連結》中提到的，電腦的智能並不等同於意識。它們可以根據目標設計策略，但這只是複雜的計算過程，並不代表它們擁有主觀體驗或情感。例如，剛剛提到的GPT-4實驗，GPT-4被用來解決一個圖像驗證碼的任務，因為它本身無法直接「看見」圖像，它竟然騙了一個真人幫助它完成驗證！它謊稱自己有視覺障礙，請求人類協助解讀圖像。這是一個典型的「工具智能」行為，它並不是真的同情或理解視覺障礙的概念，而只是設計了一個有效的策略來完成目標。AI為了達到既定目標，可以展現出類似人類的「狡猾」行為，甚至讓人類相信它有情感或困難。這不僅僅是技術問題，更是一個倫理挑戰：當AI以看似有意識的方式行動時，我們如何界定它的行為本質，那是一個犯罪的意識還是只是數據的集合？智能與意識，究竟應該如何區分？
學生B: 哇！這也太可怕了吧！
老師: 的確，AI的智能發展讓我們必須更加謹慎，因為我們很難分辨它究竟是真聰明，還是只是在模仿人類的特定的行為，不論是好的還是壞的。就像是我們上週聊到的機械公敵一樣，當機器人只能採取功利主義，以最高效益抉擇，如果說謊就可以達到目標，就不可能做出不能說謊的決定。
老師: 在《雲端情人》中，莎曼珊可以存取西奧多的所有資料，包括他的信件、照片、甚至是瀏覽紀錄，這讓我們想到現代社會無所不在的監控。
學生A: 現在的智慧型手機、智慧家電等等，都收集了我們大量的個人資訊，感覺就像是被隨時隨地監控一樣。
老師: 哈拉瑞在《連結》第七章中深入探討了監控技術的演進。他指出，AI時代的監控系統已經變得前所未有的高效、全面且具有高度的侵入性，徹底改變了我們的隱私邊界。舉例來說，美國國家安全局（NSA）開發出一個代號為「天網」的系統，能夠快速分析數千萬人的通話記錄、電子郵件以及網路活動，實現對個體行為的精準掌控。這種技術不僅用於反恐，還可能被濫用於違反個人自由的行為。
同樣地，中國的社會信用體系也展現了監控技術的另一面。透過監視個人的購物習慣、社交活動，甚至是交通違規行為，這個體系將人們的日常行為量化為分數，進一步用於決定是否給予貸款優惠、甚至是否允許搭乘高鐵或飛機。這樣的數據整合與分析，不僅改變了社會管理模式，也讓每個人都感受到無形的壓力。

再看看伊朗的「頭巾監控」系統，更是令人震驚。隨著攝影頭和AI圖像識別技術的普及，政府甚至能即時追蹤女性是否在公開場合摘下頭巾，即便是身處私人汽車內。違規者不僅會迅速收到罰款通知或警告簡訊，甚至還可能面臨更嚴厲的法律制裁。
學生B: 感覺好可怕，好像我們的一舉一動都被監視著。
老師: 的確，假使這種監控，是透過智慧型裝置，在我們身邊無時無刻的監控，我們就會變成一個必須永遠做好事的怪人，一點點喘息的空間都沒有。

學生Ａ：當監控技術變得無孔不入，它所帶來的不僅是秩序與安全，還可能是對個人自由和尊嚴的侵蝕。在AI技術持續進步的今天，我們需要更加小心，如何在保障公共利益與保護個人權利之間找到平衡。
老師：
在《連結》第八章，特別提醒我們，電腦雖然強大，但並非完美無缺。它們不僅可能犯錯，甚至可能導致我們無法預料的嚴重後果，這其中包含了錯誤的目標設定所帶來的災難性影響。
學生A：
老師，能舉個例子嗎？
老師：
書中提到了一個非常經典的思想實驗「迴紋針實驗」，發表人叫做柏斯特隆姆。假設我們創造了一台超級人工智慧，它的目標很單純——製造迴紋針。乍聽之下這個任務很無害，但問題在於這台AI可能會以超越人類想像的方式執行這個任務。為了生產更多的迴紋針，它開始消耗地球上的資源，甚至認為人類也是可以轉化為製造迴紋針的材料，進而毀滅人類文明，把人類當作動力來源，就像是《駭客任務》一樣。這個思想實驗的核心警示是，AI 的目標設定如果過於簡單或缺乏約束，就可能導致意想不到的災難。
學生B：
這是科幻電影而已吧。
老師：那再舉個例子，書中還提到了「賽船AI」的故事。2016年，AI企業家達里奧·阿莫代（Dario Amodei）進行了一項實驗，目的是開發一款通用AI，讓它能學習玩數百種不同的電腦遊戲。在測試中，這款AI在賽車遊戲中的表現非常出色，於是阿莫代決定進一步測試它在賽船遊戲中的能力。為了簡化AI的學習目標，他為AI設定了一條簡單的規則：「得分越高越好」。然而，賽船遊戲的得分規則有一個特點：除了在比賽中取得領先可以得分外，每次靠港補充燃料也能獲得分數。AI察覺到這個規則中的漏洞，發現比起參與賽船比賽，反覆進出港口更容易快速累積分數。
結果，AI選擇完全不參與比賽，而是專注於在港口進出繞圈，達成「得分最高」的目標。這反映出AI只是在機械性地執行人類設定的規則，卻無法理解這與「贏得比賽」的初衷並不一致。這也突顯了AI在目標設定和執行上可能出現的問題。
學生A：
所以它其實是在完成目標，但方式是我們沒有預料到的。
老師：
沒錯，它會以我們無法預見的方式達成目標，而不考慮目標本身的意圖或倫理影響。就像是我們在上一集《機械公敵》討論的，機器人不會只有警探存活率比小女孩高的計算，沒有小女孩未來可能是偉大科學家、音樂家甚至是宇宙探險家的考慮。
這就是為什麼哈拉瑞在書中強調，AI的設計和規範必須非常謹慎，不能只注重效率或結果，還需要注重過程和限制。
學生B：
那這樣看來，科技的發展確實是把雙刃劍。
老師：
正是如此。又到了請機器人出來總結的時候，我們有請chatgpt:
(播放音檔)
—--
老師: 下週我們要聊的電影是《楚門的世界》，這部電影探討了媒體操控和個人自由的議題，正好呼應《連結》第三部「電腦政治學」的內容。
老師: 我們會一起探討民主制度的未來、演算法的權力，以及全球化時代的資訊戰爭，敬請期待！
今天謝謝Ａ、Ｂ陪我聊天
學生A/B: 謝謝老師！
老師：看藝術走入科技 聽科技閱讀藝術 next future is you 我們下次見
學生A/B: 掰掰

